\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{pandasprofiling2019}
\HyPL@Entry{0<</S/D>>}
\providecommand \oddpage@label [2]{}
\providecommand\tcolorbox@label[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Exploratory Analysis}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Investigating Binary Variables}{2}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Stacked bar plots between price and some binary variables\relax }}{2}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{binary}{{1}{2}{Stacked bar plots between price and some binary variables\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Investigating Categorical Variables}{2}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Stacked bar plots between price and some categorical variables\relax }}{3}{figure.caption.2}}
\newlabel{categorical}{{2}{3}{Stacked bar plots between price and some categorical variables\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Investigating Numerical Variables}{3}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Boxplots between price and some numerical variables\relax }}{4}{figure.caption.3}}
\newlabel{numerical}{{3}{4}{Boxplots between price and some numerical variables\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data Splits}{4}{section.3}}
\citation{PyCaret}
\citation{ho1998random}
\citation{ho1998random}
\citation{ho1998random}
\citation{ho1998random}
\citation{scikit-learn}
\@writefile{toc}{\contentsline {section}{\numberline {4}Models}{5}{section.4}}
\citation{friedman2002stochastic}
\citation{friedman2002stochastic}
\citation{friedman2002stochastic}
\citation{friedman2002stochastic}
\citation{friedman2002stochastic}
\citation{chen2015xgboost}
\citation{chen2015xgboost}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Baseline classification models. Results are based on 10-fold cross-validation on my training set (6776 records). Table is sorted by accuracy. Certain models are prevented for comparison because of their longer run-time.\relax }}{6}{table.caption.4}}
\newlabel{table:baseline}{{1}{6}{Baseline classification models. Results are based on 10-fold cross-validation on my training set (6776 records). Table is sorted by accuracy. Certain models are prevented for comparison because of their longer run-time.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Training}{6}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1} Random Forest Classifier}{6}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2} Gradient Boosting Classifier }{6}{subsection.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3} XGBoost Classifier}{7}{subsection.5.3}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Hyperparameter Selection}{7}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1} Random Forest Classifier}{7}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cross-validation accuracy using Random Forest Classifier on my training set (6776 records).\relax }}{7}{figure.caption.5}}
\newlabel{cv_rf}{{4}{7}{Cross-validation accuracy using Random Forest Classifier on my training set (6776 records).\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2} Gradient Boosting Classifier }{7}{subsection.6.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Cross-validation accuracy using Gradient Boosting Classifier on my training set (6776 records).\relax }}{8}{figure.caption.6}}
\newlabel{cv_gbc}{{5}{8}{Cross-validation accuracy using Gradient Boosting Classifier on my training set (6776 records).\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3} XGBoost Classifier}{8}{subsection.6.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Cross-validation accuracy using XGBoost Classifier on my training set (6776 records).\relax }}{8}{figure.caption.7}}
\newlabel{cv_xgbc}{{6}{8}{Cross-validation accuracy using XGBoost Classifier on my training set (6776 records).\relax }{figure.caption.7}{}}
\citation{boehmke2019hands}
\citation{boehmke2019hands}
\citation{van2007super}
\@writefile{toc}{\contentsline {section}{\numberline {7} Stacked Models}{9}{section.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Stacked Models\relax }}{9}{figure.caption.8}}
\newlabel{stacked}{{7}{9}{Stacked Models\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Errors and Mistakes}{9}{section.8}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Predictive Accuracy}{10}{section.9}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Categorization accuracy of models on the training set and the test set. Out-of-sample accuracy was obtained on my test set (2905 records). Note that test accuracy was obtained from Kaggle (based on 30\% of test set). For each model, I've submitted several versions to Kaggle and the results here in test accuracy are the best among each model.\relax }}{10}{table.caption.9}}
\newlabel{compare}{{2}{10}{Categorization accuracy of models on the training set and the test set. Out-of-sample accuracy was obtained on my test set (2905 records). Note that test accuracy was obtained from Kaggle (based on 30\% of test set). For each model, I've submitted several versions to Kaggle and the results here in test accuracy are the best among each model.\relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confusion matrix of the stacked model of 7 base learners on my test data (2905 records).\relax }}{10}{figure.caption.10}}
\newlabel{confusionmatrix}{{8}{10}{Confusion matrix of the stacked model of 7 base learners on my test data (2905 records).\relax }{figure.caption.10}{}}
\bibstyle{unsrt}
\bibdata{lit}
\bibcite{pandasprofiling2019}{1}
\bibcite{PyCaret}{2}
\bibcite{ho1998random}{3}
\bibcite{scikit-learn}{4}
\bibcite{friedman2002stochastic}{5}
\bibcite{chen2015xgboost}{6}
\bibcite{boehmke2019hands}{7}
\bibcite{van2007super}{8}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces AUC curve for the stacked model of 7 base learners on my test data (2905 records).\relax }}{11}{figure.caption.11}}
\newlabel{auc}{{9}{11}{AUC curve for the stacked model of 7 base learners on my test data (2905 records).\relax }{figure.caption.11}{}}
